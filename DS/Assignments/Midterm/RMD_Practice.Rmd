---
title: "Panel_Info_Crawling"
output: html_document
---



### Extra Research for "Start A Start-up" Class

Basic research concerning the **'Panel survey part time jobs'** will be conducted here, using the R markdown. The list below are the things to be done in this markdown.

- The overview of the website we are interested in
- Crawling the certain webpages of the website using **"rvest"** package



```{r PREPARE PACKAGES, message=FALSE,warning=FALSE}

# libraries
library(tidyverse)
library(httr)
library(rvest)
```

First of all, the target URL for the website we are interesting is shown as below

```{r URL , results='hide'} 
'https://www.jubumonitor.com'
```


This website is for **housewives** that provides various kinds of information for them.   In this website, we will find the _notifications on part time jobs_ and crawl the list.


### Find the Pages We Want to Ontain

Here, we are going to use the google bot user agent we learned in class.
```{r User_Agent}
 
myUA <- 'Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)'


```




```{r GET}


res <- GET (url = 'https://www.jubumonitor.com/bbs/board.php', 
           query = list(board="panel"),
           user_agent(agent = myUA))
           

# Check the response 
print(x = res)

```

Since **'Status: 200'**, we can find out the the request was successfully responded.    Next, we will use css selector to access the exact information we want to collect.

```{r }

text=
res %>%
  read_html(encoding='euc-kr') %>%
  html_nodes( css='#mainIndexTable') %>%
  html_table()



head(text[[1]],10)
```


Since the data is messy, some preprocessing seems to be needed

```{r }

text.df = text[[1]] [c(-3:-1),] [seq(1,47,2),] [,-1]
colnames(text.df)=c('id','내용','리서치 회사')

print(as.tibble(text.df))


```





